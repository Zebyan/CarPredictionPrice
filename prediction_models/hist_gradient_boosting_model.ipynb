{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dfea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/processed/train_ready.csv\")\n",
    "df.sample(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c1a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    r2_score\n",
    ")\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 1) SET TARGET\n",
    "# ====================================================\n",
    "\n",
    "X = df.drop(columns=[\"pret_log\"])\n",
    "y_log = df[\"pret_log\"]\n",
    "\n",
    "X_train, X_test, y_train_log, y_test_log = train_test_split(\n",
    "    X, y_log, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numeric_cols     = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 2) PREPROCESSING PIPELINE\n",
    "# ====================================================\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols),\n",
    "        (\"num\", \"passthrough\", numeric_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 3) HISTGRADIENTBOOSTING REGRESSOR (LIGHTWEIGHT)\n",
    "# ====================================================\n",
    "\n",
    "hgb = HistGradientBoostingRegressor(\n",
    "    max_depth=10,        # control complexity\n",
    "    learning_rate=0.05,  # smaller LR for smoother fits\n",
    "    max_leaf_nodes=64,   # limits tree size\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"hgb\", hgb)\n",
    "])\n",
    "\n",
    "print(\"Fitting HistGradientBoostingRegressor...\")\n",
    "pipeline.fit(X_train, y_train_log)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 4) METRICS\n",
    "# ====================================================\n",
    "\n",
    "y_pred_log = pipeline.predict(X_test)\n",
    "y_pred     = np.expm1(y_pred_log)\n",
    "y_true     = np.expm1(y_test_log)\n",
    "\n",
    "rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_log))\n",
    "r2_log   = r2_score(y_test_log, y_pred_log)\n",
    "\n",
    "rmse_price = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mae_price  = mean_absolute_error(y_true, y_pred)\n",
    "mape       = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "accuracy   = 100 - mape\n",
    "r2_price   = r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "print(\"\\n=== PRICE Metrics (EUR) ===\")\n",
    "print(f\"RMSE_price: {rmse_price:,.2f} EUR\")\n",
    "print(f\"MAE_price:  {mae_price:,.2f} EUR\")\n",
    "print(f\"R2_price:   {r2_price:.4f}\")\n",
    "print(f\"  MAPE    : {mape:.2f}%\")\n",
    "print(f\"  Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# ====================================================\n",
    "# 6) 20 RANDOM SAMPLE PREDICTIONS\n",
    "# ====================================================\n",
    "results = pd.DataFrame({\n",
    "    \"true_price\": y_true,\n",
    "    \"pred_price\": y_pred,\n",
    "})\n",
    "\n",
    "results[\"abs_error\"]  = (results[\"true_price\"] - results[\"pred_price\"]).abs()\n",
    "results[\"pct_error\"]  = results[\"abs_error\"] / results[\"true_price\"] * 100\n",
    "\n",
    "print(\"\\n=== 20 random predictions (EUR) ===\")\n",
    "print(\n",
    "    results\n",
    "    .sample(20, random_state=42)\n",
    "    .round({\"true_price\": 0, \"pred_price\": 0, \"abs_error\": 0, \"pct_error\": 2})\n",
    ")\n",
    "\n",
    "# ====================================================\n",
    "# 7) FEATURE IMPORTANCES\n",
    "# ====================================================\n",
    "rf_best = hgb.named_steps[\"rf\"]\n",
    "feature_names = hgb.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": rf_best.feature_importances_,\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 important features:\")\n",
    "print(importances.head(20))\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 5) SAVE MODEL (OVERWRITE OLD RF MODEL)\n",
    "# ====================================================\n",
    "\n",
    "os.makedirs(\"backend/models_storage/metadata\", exist_ok=True)\n",
    "model_path = \"backend/models_storage/hist_gradient_boosting.pkl\"\n",
    "\n",
    "joblib.dump(pipeline, model_path)\n",
    "model_size_mb = os.path.getsize(model_path) / 1024 / 1024\n",
    "\n",
    "print(f\"\\nModel saved to {model_path} ({model_size_mb:.2f} MB)\")\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 6) SAVE METADATA (SAME PATTERN)\n",
    "# ====================================================\n",
    "\n",
    "metadata = {\n",
    "    \"saved_at\": datetime.now().isoformat(),\n",
    "    \"model_type\": \"HistGradientBoostingRegressor\",\n",
    "    \"tuning_method\": \"manual_fixed_params\",\n",
    "    \"best_parameters\": {\n",
    "        \"max_depth\": 10,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_leaf_nodes\": 64,\n",
    "        \"random_state\": 42,\n",
    "    },\n",
    "    \"performance_metrics\": {\n",
    "        \"rmse_log\": float(rmse_log),\n",
    "        \"r2_log\": float(r2_log),\n",
    "        \"rmse_price_eur\": float(rmse_price),\n",
    "        \"mae_price_eur\": float(mae_price),\n",
    "        \"mape_percent\": float(mape),\n",
    "        \"accuracy_percent\": float(accuracy),\n",
    "    },\n",
    "    \"training_info\": {\n",
    "        \"train_samples\": int(len(X_train)),\n",
    "        \"test_samples\": int(len(X_test)),\n",
    "        \"total_features_raw\": int(X.shape[1]),\n",
    "        \"categorical_features\": categorical_cols,\n",
    "        \"numeric_features\": numeric_cols,\n",
    "    },\n",
    "    \"paths\": {\n",
    "        \"model_path\": model_path,\n",
    "    },\n",
    "}\n",
    "\n",
    "metadata_path = \"backend/models_storage/metadata/hist_gradient_boosting_metadata.json\"\n",
    "with open(metadata_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Metadata saved to {metadata_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
